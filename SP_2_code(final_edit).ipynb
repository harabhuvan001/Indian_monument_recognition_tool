{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xF_A1h9Up3qB"
      },
      "outputs": [],
      "source": [
        "!pip install gradio tensorflow numpy requests\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNqgZxVAqmVc"
      },
      "source": [
        "Gradio\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7zIH097yv8cl",
        "outputId": "a5f07a5c-527a-4052-9cae-b82b97a968f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94668760/94668760 [==============================] - 4s 0us/step\n",
            "Found 3672 images belonging to 24 classes.\n",
            "Found 1058 images belonging to 24 classes.\n",
            "Epoch 1/10\n",
            "115/115 [==============================] - 1804s 16s/step - loss: 1.4111 - accuracy: 0.6296 - val_loss: 2.9807 - val_accuracy: 0.4887\n",
            "Epoch 2/10\n",
            "115/115 [==============================] - 477s 4s/step - loss: 0.5119 - accuracy: 0.8794 - val_loss: 3.4093 - val_accuracy: 0.5009\n",
            "Epoch 3/10\n",
            "115/115 [==============================] - 481s 4s/step - loss: 0.3530 - accuracy: 0.9120 - val_loss: 3.7778 - val_accuracy: 0.5161\n",
            "Epoch 4/10\n",
            "115/115 [==============================] - 426s 4s/step - loss: 0.2795 - accuracy: 0.9325 - val_loss: 4.0266 - val_accuracy: 0.5057\n",
            "Epoch 5/10\n",
            "115/115 [==============================] - 474s 4s/step - loss: 0.2243 - accuracy: 0.9496 - val_loss: 4.1935 - val_accuracy: 0.5198\n",
            "Epoch 6/10\n",
            "115/115 [==============================] - 476s 4s/step - loss: 0.1931 - accuracy: 0.9559 - val_loss: 4.4773 - val_accuracy: 0.5302\n",
            "Epoch 7/10\n",
            "115/115 [==============================] - 425s 4s/step - loss: 0.1672 - accuracy: 0.9602 - val_loss: 4.7874 - val_accuracy: 0.5208\n",
            "Epoch 8/10\n",
            "115/115 [==============================] - 425s 4s/step - loss: 0.1515 - accuracy: 0.9641 - val_loss: 4.8204 - val_accuracy: 0.5208\n",
            "Epoch 9/10\n",
            "115/115 [==============================] - 475s 4s/step - loss: 0.1212 - accuracy: 0.9744 - val_loss: 4.9075 - val_accuracy: 0.5236\n",
            "Epoch 10/10\n",
            "115/115 [==============================] - 476s 4s/step - loss: 0.1183 - accuracy: 0.9722 - val_loss: 5.1253 - val_accuracy: 0.5208\n",
            "34/34 [==============================] - 90s 3s/step - loss: 5.1253 - accuracy: 0.5208\n",
            "Test loss: 5.1253\n",
            "Test accuracy: 0.5208\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.resnet_v2 import ResNet50V2, preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Load the pre-trained model\n",
        "base_model = ResNet50V2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze the layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add a new output layer\n",
        "num_classes = 24  # replace with the number of Indian monuments you have\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
        "output = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "# Create the new model\n",
        "model = tf.keras.models.Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define the image generators for training and testing\n",
        "train_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        "    rotation_range=20,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "# Define the paths to your train and test data sets\n",
        "train_dir = '/content/drive/MyDrive/images/train'\n",
        "test_dir = '/content/drive/MyDrive/images/test'\n",
        "\n",
        "# Set the batch size\n",
        "batch_size = 32\n",
        "\n",
        "# Create the image generators\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=10,  # replace with the number of epochs you want to train for\n",
        "    steps_per_epoch=len(train_generator),\n",
        "    validation_data=test_generator,\n",
        "    validation_steps=len(test_generator)\n",
        ")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "loss, accuracy = model.evaluate(test_generator, steps=len(test_generator))\n",
        "print(f'Test loss: {loss:.4f}')\n",
        "print(f'Test accuracy: {accuracy:.4f}')\n",
        "\n",
        "# Save the model\n",
        "model.save('/content/drive/MyDrive/images/IMR.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xxw8AsODrybN"
      },
      "outputs": [],
      "source": [
        "!pip install ipywidgets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "_S_4V2kED_dr",
        "outputId": "05020834-465f-4f84-b9ea-0486abb98773"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "Based on my analysis, this looks like:  Lotus Temple - A Bahá'í House of Worship located in New Delhi, India\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "Based on my analysis, this looks like:  Taj Mahal - A mausoleum located in Agra, Uttar Pradesh, India\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the pre-trained model\n",
        "model = load_model('/content/drive/MyDrive/images/IMR.h5')\n",
        "\n",
        "# Define a function to preprocess the input image\n",
        "def preprocess_image(image_path):\n",
        "    # Load the image and convert to RGB format\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Resize the image to the input size of the model\n",
        "    resized = cv2.resize(image, (224, 224), interpolation=cv2.INTER_AREA)\n",
        "\n",
        "    # Reshape the image to match the input shape of the model\n",
        "    reshaped = np.reshape(resized, (1, 224, 224, 3))\n",
        "\n",
        "    # Normalize the pixel values to be between 0 and 1\n",
        "    normalized = reshaped / 255.0\n",
        "\n",
        "    return normalized\n",
        "\n",
        "# Define a function to predict the name of the monument\n",
        "def predict_monument(image_path):\n",
        "    # Preprocess the input image\n",
        "    preprocessed_image = preprocess_image(image_path)\n",
        "\n",
        "    # Make a prediction using the model\n",
        "    prediction = model.predict(preprocessed_image)\n",
        "\n",
        "    # Get the index of the predicted class\n",
        "    predicted_class = np.argmax(prediction)\n",
        "\n",
        "    # Map the index to the corresponding monument name\n",
        "    if predicted_class == 0:\n",
        "        return \"Bibi Ka Maqbara - A tomb built in the 17th century in Aurangabad, Maharashtra, India\"\n",
        "    elif predicted_class == 1:\n",
        "        return \"Charminar - A monument and mosque located in Hyderabad, Telangana, India\"\n",
        "    elif predicted_class == 2:\n",
        "        return \"Gol Gumbaz - A mausoleum located in Bijapur, Karnataka, India\"\n",
        "    elif predicted_class == 3:\n",
        "        return \"Hawa Mahal - A palace located in Jaipur, Rajasthan, India\"\n",
        "    elif predicted_class == 4:\n",
        "        return \"Kanch Mahal - A palace located in New Delhi, India\"\n",
        "    elif predicted_class == 5:\n",
        "        return \"Lotus Temple - A Bahá'í House of Worship located in New Delhi, India\"\n",
        "    elif predicted_class == 6:\n",
        "        return \"Parliament - The Parliament of India located in New Delhi, India\"\n",
        "    elif predicted_class == 7:\n",
        "        return \"Red Fort - A historical fort located in Delhi, India\"\n",
        "    elif predicted_class == 8:\n",
        "        return \"Taj Mahal - A mausoleum located in Agra, Uttar Pradesh, India\"\n",
        "    else:\n",
        "        return \"Unknown monument\"\n",
        "\n",
        "\n",
        "# Define a function to prompt the user for an image and return the predicted monument\n",
        "def predict_from_input():\n",
        "    # Prompt the user to input the image path\n",
        "    image_path = input(\"Hello! Please upload an image of a monument you'd like me to identify: \")\n",
        "\n",
        "    # Predict the monument name based on the image\n",
        "    predicted_monument = predict_monument(image_path)\n",
        "\n",
        "    # Print the predicted monument name\n",
        "    print(\"Based on my analysis, this looks like: \", predicted_monument)\n",
        "\n",
        "    # Ask the user if they want to predict another image\n",
        "    another_image = input(\"Do you want to identify another monument? (yes or no): \")\n",
        "\n",
        "    # If the user wants to predict another image, call this function recursively\n",
        "    if another_image.lower() == 'yes':\n",
        "        predict_from_input()\n",
        "    else:\n",
        "        print(\"Thank you for using our monument recognition chatbot\")\n",
        "    \n",
        "# Call the predict_from_input function to start the chatbot\n",
        "predict_from_input()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BQKltLWeNMR",
        "outputId": "99674bc5-08d9-474a-876a-ee771b3b4967"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flask-ngrok\n",
        "!pip install pyngrok\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84urowkHFrxg",
        "outputId": "863531eb-f7f8-4fba-e074-bbd0816ced60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: flask-ngrok in /usr/local/lib/python3.10/dist-packages (0.0.25)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.10/dist-packages (from flask-ngrok) (2.2.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from flask-ngrok) (2.27.1)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask-ngrok) (2.3.0)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask-ngrok) (3.1.2)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask-ngrok) (2.1.2)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask-ngrok) (8.1.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->flask-ngrok) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->flask-ngrok) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->flask-ngrok) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->flask-ngrok) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->Flask>=0.8->flask-ngrok) (2.1.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-6.0.0.tar.gz (681 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m681.2/681.2 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0)\n",
            "Building wheels for collected packages: pyngrok\n",
            "  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyngrok: filename=pyngrok-6.0.0-py3-none-any.whl size=19867 sha256=567d95b45663ea4c180d313480df2812d85e4e96ae0e0f402bb49de0d60910e3\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/42/78/0c3d438d7f5730451a25f7ac6cbf4391759d22a67576ed7c2c\n",
            "Successfully built pyngrok\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-6.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok authtoken 2PQbAG2hWfpylkRtMSoftDxJePU_6dEaVfWfzRd2jx9gDhpU2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJvHdeBbHwHB",
        "outputId": "587ca39b-9f70-443b-adfa-0fe9f3894633"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from flask import Flask, request\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route('/', methods=['GET'])\n",
        "def index():\n",
        "    return 'Hello! Please upload an image of a monument you\\'d like me to identify.'\n",
        "\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    # Get the image file from the request\n",
        "    file = request.files['file']\n",
        "\n",
        "    # Save the image file\n",
        "    file_path = 'image.jpg'\n",
        "    file.save(file_path)\n",
        "\n",
        "    # Predict the monument name based on the image\n",
        "    predicted_monument = predict_monument(file_path)\n",
        "\n",
        "    # Return the predicted monument name\n",
        "    return predicted_monument\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Run the app with ngrok\n",
        "    from pyngrok import ngrok\n",
        "    ngrok_tunnel = ngrok.connect(5000)\n",
        "    print('Public URL:', ngrok_tunnel.public_url)\n",
        "\n",
        "    # Start the Flask app\n",
        "    app.run(port=5000)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CdfuPc_KydJ",
        "outputId": "6052d4f9-eaef-40df-924a-070b86a1cbe7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2023-05-10T10:19:35+0000 lvl=warn msg=\"ngrok config file found at legacy location, move to XDG location\" xdg_path=/root/.config/ngrok/ngrok.yml legacy_path=/root/.ngrok2/ngrok.yml\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: https://0c74-35-202-253-165.ngrok-free.app\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "from flask import Flask, jsonify, request\n",
        "import requests\n",
        "import json\n",
        "from flask_ngrok import run_with_ngrok\n",
        "\n",
        "# Load the pre-trained model\n",
        "model = load_model('/content/drive/MyDrive/images/IMR.h5')\n",
        "\n",
        "# Define a function to preprocess the input image\n",
        "def preprocess_image(image_path):\n",
        "    # Load the image and convert to RGB format\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Resize the image to the input size of the model\n",
        "    resized = cv2.resize(image, (224, 224), interpolation=cv2.INTER_AREA)\n",
        "\n",
        "    # Reshape the image to match the input shape of the model\n",
        "    reshaped = np.reshape(resized, (1, 224, 224, 3))\n",
        "\n",
        "    # Normalize the pixel values to be between 0 and 1\n",
        "    normalized = reshaped / 255.0\n",
        "\n",
        "    return normalized\n",
        "\n",
        "# Define a function to predict the name of the monument\n",
        "def predict_monument(image_path):\n",
        "  \n",
        "    # Preprocess the input image\n",
        "    preprocessed_image = preprocess_image(image_path)\n",
        "\n",
        "    # Make a prediction using the model\n",
        "    prediction = model.predict(preprocessed_image)\n",
        "\n",
        "    # Get the index of the predicted class\n",
        "    predicted_class = np.argmax(prediction)\n",
        "\n",
        "    # Map the index to the corresponding monument name\n",
        "    if predicted_class == 0:\n",
        "        return \"Bibi Ka Maqbara - A tomb built in the 17th century in Aurangabad, Maharashtra, India\"\n",
        "    elif predicted_class == 1:\n",
        "        return \"Charminar - A monument and mosque located in Hyderabad, Telangana, India\"\n",
        "\n",
        "    else:\n",
        "        return \"Unknown monument\"\n",
        "\n",
        "# Initialize the Flask app\n",
        "app = Flask(__name__)\n",
        "run_with_ngrok(app)  # Start ngrok when the app is run\n",
        "\n",
        "# Define a route for the home page\n",
        "@app.route('/')\n",
        "def home():\n",
        "    return 'Monument recognition chatbot is running!'\n",
        "\n",
        "# Define a route for predicting the monument from an input image\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    # Get the image file from the request\n",
        "    image_file = request.files['image']\n",
        "\n",
        "    # Save the image file to disk\n",
        "    image_path = 'input_image.jpg'\n",
        "    image_file.save(image_path)\n",
        "\n",
        "    # Predict the monument name based on the image\n",
        "    predicted_monument = predict_monument(image_path)\n",
        "\n",
        "    # Return the predicted monument name as a JSON response\n",
        "    return jsonify({'monument': predicted_monument})\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run()  # Run the Flask app\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEvVgeB3EiSE",
        "outputId": "0ffe5360-6f64-469b-c251-a559a4d46ec1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Running on http://2474-35-202-253-165.ngrok-free.app\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [10/May/2023 10:20:18] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [10/May/2023 10:20:19] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}